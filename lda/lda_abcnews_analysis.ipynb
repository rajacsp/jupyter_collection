{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source https://github.com/susanli2016/NLP-with-Python/blob/master/LDA_news_headlines.ipynb\n",
    "# https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('p:/datasets/abcnews-date-text.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219  aba decides against community broadcasting lic...\n",
       "1      20030219     act fire witnesses must be aware of defamation\n",
       "2      20030219     a g calls for infrastructure protection summit\n",
       "3      20030219           air nz staff in aust strike for pay rise\n",
       "4      20030219      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.082168e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.009838e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.996017e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.003022e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.006113e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.010053e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.013082e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.017063e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       publish_date\n",
       "count  1.082168e+06\n",
       "mean   2.009838e+07\n",
       "std    3.996017e+04\n",
       "min    2.003022e+07\n",
       "25%    2.006113e+07\n",
       "50%    2.010053e+07\n",
       "75%    2.013082e+07\n",
       "max    2.017063e+07"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data[['headline_text']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1082168"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ambitious olsson wins triple jump</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>antic delighted with record breaking barca</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aussie qualifier stosur wastes four memphis match</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aust addresses un security council over iraq</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>australia is locked into war timetable opp</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>australia to contribute 10 million in aid to iraq</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>barca take record as robson celebrates birthda...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bathhouse plans move ahead</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>big hopes for launceston cycling championship</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>big plan to boost paroo water supplies</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        headline_text  index\n",
       "0   aba decides against community broadcasting lic...      0\n",
       "1      act fire witnesses must be aware of defamation      1\n",
       "2      a g calls for infrastructure protection summit      2\n",
       "3            air nz staff in aust strike for pay rise      3\n",
       "4       air nz strike to affect australian travellers      4\n",
       "5                   ambitious olsson wins triple jump      5\n",
       "6          antic delighted with record breaking barca      6\n",
       "7   aussie qualifier stosur wastes four memphis match      7\n",
       "8        aust addresses un security council over iraq      8\n",
       "9          australia is locked into war timetable opp      9\n",
       "10  australia to contribute 10 million in aid to iraq     10\n",
       "11  barca take record as robson celebrates birthda...     11\n",
       "12                         bathhouse plans move ahead     12\n",
       "13      big hopes for launceston cycling championship     13\n",
       "14             big plan to boost paroo water supplies     14"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\infoadmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "print(WordNetLemmatizer().lemmatize('went', pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denied</td>\n",
       "      <td>deni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humbled</td>\n",
       "      <td>humbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word stemmed\n",
       "0       caresses  caress\n",
       "1          flies     fli\n",
       "2           dies     die\n",
       "3          mules    mule\n",
       "4         denied    deni\n",
       "5           died     die\n",
       "6         agreed    agre\n",
       "7          owned     own\n",
       "8        humbled   humbl\n",
       "9          sized    size\n",
       "10       meeting    meet\n",
       "11       stating   state\n",
       "12       siezing    siez\n",
       "13   itemization    item\n",
       "14   sensational  sensat\n",
       "15   traditional  tradit\n",
       "16     reference   refer\n",
       "17     colonizer   colon\n",
       "18       plotted    plot"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "pd.DataFrame(data = {'original word': original_words, 'stemmed': singles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>rain helps dampen bushfires</td>\n",
       "      <td>4310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    headline_text  index\n",
       "4310  rain helps dampen bushfires   4310"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[documents['index'] == 4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rain helps dampen bushfires'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[documents['index'] == 4310].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['rain', 'helps', 'dampen', 'bushfires']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['rain', 'help', 'dampen', 'bushfir']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "    \n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          aba decides against community broadcasting lic...\n",
       "1             act fire witnesses must be aware of defamation\n",
       "2             a g calls for infrastructure protection summit\n",
       "3                   air nz staff in aust strike for pay rise\n",
       "4              air nz strike to affect australian travellers\n",
       "5                          ambitious olsson wins triple jump\n",
       "6                 antic delighted with record breaking barca\n",
       "7          aussie qualifier stosur wastes four memphis match\n",
       "8               aust addresses un security council over iraq\n",
       "9                 australia is locked into war timetable opp\n",
       "10         australia to contribute 10 million in aid to iraq\n",
       "11         barca take record as robson celebrates birthda...\n",
       "12                                bathhouse plans move ahead\n",
       "13             big hopes for launceston cycling championship\n",
       "14                    big plan to boost paroo water supplies\n",
       "15                    blizzard buries united states in bills\n",
       "16            brigadier dismisses reports troops harassed in\n",
       "17            british combat troops arriving daily in kuwait\n",
       "18                bryant leads lakers to double overtime win\n",
       "19                  bushfire victims urged to see centrelink\n",
       "20           businesses should prepare for terrorist attacks\n",
       "21           calleri avenges final defeat to eliminate massu\n",
       "22                   call for ethanol blend fuel to go ahead\n",
       "23                    carews freak goal leaves roma in ruins\n",
       "24                              cemeteries miss out on funds\n",
       "25         code of conduct toughens organ donation regula...\n",
       "26              commonwealth bank cuts fixed home loan rates\n",
       "27                    community urged to help homeless youth\n",
       "28          council chief executive fails to secure position\n",
       "29           councillor to contest wollongong as independent\n",
       "                                 ...                        \n",
       "1082138     sydney college found guilty of scamming students\n",
       "1082139            sydney parcel bomb trial brings hung jury\n",
       "1082140              sydney play group versus the developers\n",
       "1082141    taffy the 1970s telecommunications union card ...\n",
       "1082142    tas inquest troy monson robin michael scott mi...\n",
       "1082143    tas labor accused of middle eastern dress code...\n",
       "1082144             tax return things you can and cant claim\n",
       "1082145         teenagers porn use on the rise research says\n",
       "1082146             tehan announces information warfare unit\n",
       "1082147    tenneco australia to close adelaide exhaust plant\n",
       "1082148    tensions high in hong kong ahead of handover a...\n",
       "1082149                              the drum friday june 30\n",
       "1082150                                   the vicious circle\n",
       "1082151    this fruit fly could cause $1 billion damage t...\n",
       "1082152        tips on how to avoid deep vein thrombosis dvt\n",
       "1082153    tony abbott urged to wind back nuclear submari...\n",
       "1082154    trumps mika brzezinski insults draw strong rep...\n",
       "1082155                   trump tweets his glee at fake news\n",
       "1082156    venus williams caused fatal car crash police r...\n",
       "1082157    victoria liberals religious right branch stack...\n",
       "1082158        victoria records driest start to winter since\n",
       "1082159     wa prescription drug busts up reveal wider abuse\n",
       "1082160    west gate tunnel project a dogs breakfast coun...\n",
       "1082161       what happens when you call the poisons hotline\n",
       "1082162                               what now for trumpcare\n",
       "1082163    when is it ok to compliment a womans smile a g...\n",
       "1082164                     white house defends trumps tweet\n",
       "1082165       winter closes in on tasmania as snow ice falls\n",
       "1082166    womens world cup australia wins despite atapat...\n",
       "1082167            youtube stunt death foreshadowed by tweet\n",
       "Name: headline_text, Length: 1082168, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents['headline_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents['headline_text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [decid, communiti, broadcast, licenc]\n",
       "1                               [wit, awar, defam]\n",
       "2           [call, infrastructur, protect, summit]\n",
       "3                      [staff, aust, strike, rise]\n",
       "4             [strike, affect, australian, travel]\n",
       "5               [ambiti, olsson, win, tripl, jump]\n",
       "6           [antic, delight, record, break, barca]\n",
       "7    [aussi, qualifi, stosur, wast, memphi, match]\n",
       "8            [aust, address, secur, council, iraq]\n",
       "9                         [australia, lock, timet]\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs) # Initialize the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 broadcast\n",
      "1 communiti\n",
      "2 decid\n",
      "3 licenc\n",
      "4 awar\n",
      "5 defam\n",
      "6 wit\n",
      "7 call\n",
      "8 infrastructur\n",
      "9 protect\n",
      "10 summit\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(76, 1), (112, 1), (483, 1), (4009, 1)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1)],\n",
       " [(4, 1), (5, 1), (6, 1)],\n",
       " [(7, 1), (8, 1), (9, 1), (10, 1)],\n",
       " [(11, 1), (12, 1), (13, 1), (14, 1)],\n",
       " [(14, 1), (15, 1), (16, 1), (17, 1)]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(76, 1), (112, 1), (483, 1), (4009, 1)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bow_corpus[4310])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 76 (\"bushfir\") appears 1 time.\n",
      "Word 112 (\"help\") appears 1 time.\n",
      "Word 483 (\"rain\") appears 1 time.\n",
      "Word 4009 (\"dampen\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                                     dictionary[bow_doc_4310[i][0]], \n",
    "                                                     bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5902626795041239),\n",
      " (1, 0.3892065020004992),\n",
      " (2, 0.4955704490710528),\n",
      " (3, 0.5044979662918994)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.ldamulticore.LdaMulticore at 0x19c943688d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.024*\"south\" + 0.024*\"world\" + 0.019*\"coast\" + 0.018*\"australia\" + 0.016*\"women\" + 0.015*\"win\" + 0.013*\"gold\" + 0.012*\"leagu\" + 0.010*\"labor\" + 0.009*\"elect\"\n",
      "Topic: 1 \n",
      "Words: 0.020*\"final\" + 0.017*\"farmer\" + 0.015*\"budget\" + 0.014*\"meet\" + 0.012*\"say\" + 0.012*\"public\" + 0.011*\"royal\" + 0.011*\"australian\" + 0.010*\"trade\" + 0.010*\"commiss\"\n",
      "Topic: 2 \n",
      "Words: 0.021*\"market\" + 0.014*\"share\" + 0.014*\"servic\" + 0.013*\"health\" + 0.013*\"worker\" + 0.012*\"fall\" + 0.011*\"guilti\" + 0.011*\"news\" + 0.011*\"bank\" + 0.010*\"close\"\n",
      "Topic: 3 \n",
      "Words: 0.054*\"polic\" + 0.020*\"death\" + 0.020*\"perth\" + 0.016*\"miss\" + 0.014*\"shoot\" + 0.013*\"investig\" + 0.011*\"victoria\" + 0.010*\"offic\" + 0.009*\"search\" + 0.009*\"prison\"\n",
      "Topic: 4 \n",
      "Words: 0.034*\"australia\" + 0.015*\"tasmania\" + 0.013*\"record\" + 0.012*\"break\" + 0.011*\"take\" + 0.011*\"lead\" + 0.009*\"campaign\" + 0.009*\"hill\" + 0.008*\"melbourn\" + 0.008*\"storm\"\n",
      "Topic: 5 \n",
      "Words: 0.018*\"elect\" + 0.017*\"live\" + 0.012*\"turnbul\" + 0.012*\"life\" + 0.011*\"protest\" + 0.011*\"jail\" + 0.010*\"talk\" + 0.010*\"forc\" + 0.010*\"state\" + 0.009*\"polit\"\n",
      "Topic: 6 \n",
      "Words: 0.024*\"sydney\" + 0.018*\"interview\" + 0.018*\"adelaid\" + 0.014*\"arrest\" + 0.011*\"sentenc\" + 0.011*\"power\" + 0.011*\"victorian\" + 0.010*\"famili\" + 0.010*\"violenc\" + 0.009*\"hobart\"\n",
      "Topic: 7 \n",
      "Words: 0.037*\"australian\" + 0.029*\"queensland\" + 0.022*\"rural\" + 0.015*\"dead\" + 0.015*\"kill\" + 0.013*\"china\" + 0.012*\"melbourn\" + 0.011*\"releas\" + 0.009*\"bodi\" + 0.009*\"industri\"\n",
      "Topic: 8 \n",
      "Words: 0.026*\"govern\" + 0.022*\"trump\" + 0.021*\"plan\" + 0.017*\"countri\" + 0.016*\"council\" + 0.015*\"fund\" + 0.014*\"hour\" + 0.014*\"nation\" + 0.011*\"water\" + 0.010*\"communiti\"\n",
      "Topic: 9 \n",
      "Words: 0.035*\"charg\" + 0.031*\"court\" + 0.024*\"murder\" + 0.021*\"face\" + 0.018*\"die\" + 0.016*\"alleg\" + 0.016*\"accus\" + 0.015*\"child\" + 0.014*\"woman\" + 0.014*\"trial\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.008*\"juli\" + 0.006*\"island\" + 0.006*\"stori\" + 0.005*\"quiz\" + 0.005*\"breakfast\" + 0.005*\"port\" + 0.005*\"histori\" + 0.004*\"fiji\" + 0.004*\"video\" + 0.004*\"music\"\n",
      "Topic: 1 Word: 0.017*\"crash\" + 0.012*\"polic\" + 0.009*\"miss\" + 0.009*\"search\" + 0.009*\"dead\" + 0.008*\"die\" + 0.008*\"driver\" + 0.008*\"woman\" + 0.008*\"kill\" + 0.007*\"fatal\"\n",
      "Topic: 2 Word: 0.009*\"interview\" + 0.007*\"michael\" + 0.007*\"wednesday\" + 0.007*\"thursday\" + 0.006*\"decemb\" + 0.006*\"sexual\" + 0.006*\"jam\" + 0.005*\"harvest\" + 0.005*\"quarter\" + 0.005*\"open\"\n",
      "Topic: 3 Word: 0.015*\"trump\" + 0.009*\"leagu\" + 0.009*\"australia\" + 0.009*\"drum\" + 0.008*\"world\" + 0.008*\"final\" + 0.006*\"donald\" + 0.006*\"rugbi\" + 0.005*\"test\" + 0.005*\"cricket\"\n",
      "Topic: 4 Word: 0.014*\"podcast\" + 0.012*\"interview\" + 0.011*\"weather\" + 0.007*\"cattl\" + 0.007*\"octob\" + 0.007*\"live\" + 0.007*\"peter\" + 0.007*\"august\" + 0.006*\"christma\" + 0.006*\"northern\"\n",
      "Topic: 5 Word: 0.016*\"countri\" + 0.015*\"hour\" + 0.014*\"rural\" + 0.008*\"health\" + 0.007*\"fund\" + 0.007*\"nation\" + 0.006*\"plan\" + 0.006*\"council\" + 0.005*\"sport\" + 0.005*\"chang\"\n",
      "Topic: 6 Word: 0.013*\"market\" + 0.010*\"price\" + 0.009*\"share\" + 0.007*\"grandstand\" + 0.007*\"rise\" + 0.007*\"mine\" + 0.006*\"australian\" + 0.006*\"queensland\" + 0.005*\"farmer\" + 0.005*\"dairi\"\n",
      "Topic: 7 Word: 0.006*\"govern\" + 0.006*\"cancer\" + 0.006*\"climat\" + 0.006*\"john\" + 0.005*\"malcolm\" + 0.005*\"pacif\" + 0.005*\"say\" + 0.005*\"drought\" + 0.004*\"marriag\" + 0.004*\"beef\"\n",
      "Topic: 8 Word: 0.017*\"charg\" + 0.016*\"murder\" + 0.013*\"court\" + 0.012*\"news\" + 0.010*\"polic\" + 0.010*\"alleg\" + 0.009*\"assault\" + 0.008*\"accus\" + 0.008*\"guilti\" + 0.008*\"turnbul\"\n",
      "Topic: 9 Word: 0.007*\"monday\" + 0.007*\"june\" + 0.006*\"islam\" + 0.006*\"april\" + 0.006*\"capit\" + 0.006*\"kill\" + 0.005*\"attack\" + 0.005*\"obama\" + 0.005*\"social\" + 0.005*\"anim\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rain', 'help', 'dampen', 'bushfir']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.35238465666770935\t \n",
      "Topic: 0.020*\"final\" + 0.017*\"farmer\" + 0.015*\"budget\" + 0.014*\"meet\" + 0.012*\"say\" + 0.012*\"public\" + 0.011*\"royal\" + 0.011*\"australian\" + 0.010*\"trade\" + 0.010*\"commiss\"\n",
      "\n",
      "Score: 0.2873835265636444\t \n",
      "Topic: 0.034*\"australia\" + 0.015*\"tasmania\" + 0.013*\"record\" + 0.012*\"break\" + 0.011*\"take\" + 0.011*\"lead\" + 0.009*\"campaign\" + 0.009*\"hill\" + 0.008*\"melbourn\" + 0.008*\"storm\"\n",
      "\n",
      "Score: 0.2202247828245163\t \n",
      "Topic: 0.054*\"polic\" + 0.020*\"death\" + 0.020*\"perth\" + 0.016*\"miss\" + 0.014*\"shoot\" + 0.013*\"investig\" + 0.011*\"victoria\" + 0.010*\"offic\" + 0.009*\"search\" + 0.009*\"prison\"\n",
      "\n",
      "Score: 0.02000320330262184\t \n",
      "Topic: 0.026*\"govern\" + 0.022*\"trump\" + 0.021*\"plan\" + 0.017*\"countri\" + 0.016*\"council\" + 0.015*\"fund\" + 0.014*\"hour\" + 0.014*\"nation\" + 0.011*\"water\" + 0.010*\"communiti\"\n",
      "\n",
      "Score: 0.020002063363790512\t \n",
      "Topic: 0.021*\"market\" + 0.014*\"share\" + 0.014*\"servic\" + 0.013*\"health\" + 0.013*\"worker\" + 0.012*\"fall\" + 0.011*\"guilti\" + 0.011*\"news\" + 0.011*\"bank\" + 0.010*\"close\"\n",
      "\n",
      "Score: 0.020001716911792755\t \n",
      "Topic: 0.024*\"sydney\" + 0.018*\"interview\" + 0.018*\"adelaid\" + 0.014*\"arrest\" + 0.011*\"sentenc\" + 0.011*\"power\" + 0.011*\"victorian\" + 0.010*\"famili\" + 0.010*\"violenc\" + 0.009*\"hobart\"\n",
      "\n",
      "Score: 0.019999999552965164\t \n",
      "Topic: 0.024*\"south\" + 0.024*\"world\" + 0.019*\"coast\" + 0.018*\"australia\" + 0.016*\"women\" + 0.015*\"win\" + 0.013*\"gold\" + 0.012*\"leagu\" + 0.010*\"labor\" + 0.009*\"elect\"\n",
      "\n",
      "Score: 0.019999999552965164\t \n",
      "Topic: 0.018*\"elect\" + 0.017*\"live\" + 0.012*\"turnbul\" + 0.012*\"life\" + 0.011*\"protest\" + 0.011*\"jail\" + 0.010*\"talk\" + 0.010*\"forc\" + 0.010*\"state\" + 0.009*\"polit\"\n",
      "\n",
      "Score: 0.019999999552965164\t \n",
      "Topic: 0.037*\"australian\" + 0.029*\"queensland\" + 0.022*\"rural\" + 0.015*\"dead\" + 0.015*\"kill\" + 0.013*\"china\" + 0.012*\"melbourn\" + 0.011*\"releas\" + 0.009*\"bodi\" + 0.009*\"industri\"\n",
      "\n",
      "Score: 0.019999999552965164\t \n",
      "Topic: 0.035*\"charg\" + 0.031*\"court\" + 0.024*\"murder\" + 0.021*\"face\" + 0.018*\"die\" + 0.016*\"alleg\" + 0.016*\"accus\" + 0.015*\"child\" + 0.014*\"woman\" + 0.014*\"trial\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.8199766278266907\t \n",
      "Topic: 0.013*\"market\" + 0.010*\"price\" + 0.009*\"share\" + 0.007*\"grandstand\" + 0.007*\"rise\" + 0.007*\"mine\" + 0.006*\"australian\" + 0.006*\"queensland\" + 0.005*\"farmer\" + 0.005*\"dairi\"\n",
      "\n",
      "Score: 0.020004022866487503\t \n",
      "Topic: 0.014*\"podcast\" + 0.012*\"interview\" + 0.011*\"weather\" + 0.007*\"cattl\" + 0.007*\"octob\" + 0.007*\"live\" + 0.007*\"peter\" + 0.007*\"august\" + 0.006*\"christma\" + 0.006*\"northern\"\n",
      "\n",
      "Score: 0.02000393345952034\t \n",
      "Topic: 0.017*\"charg\" + 0.016*\"murder\" + 0.013*\"court\" + 0.012*\"news\" + 0.010*\"polic\" + 0.010*\"alleg\" + 0.009*\"assault\" + 0.008*\"accus\" + 0.008*\"guilti\" + 0.008*\"turnbul\"\n",
      "\n",
      "Score: 0.020003635436296463\t \n",
      "Topic: 0.006*\"govern\" + 0.006*\"cancer\" + 0.006*\"climat\" + 0.006*\"john\" + 0.005*\"malcolm\" + 0.005*\"pacif\" + 0.005*\"say\" + 0.005*\"drought\" + 0.004*\"marriag\" + 0.004*\"beef\"\n",
      "\n",
      "Score: 0.020003605633974075\t \n",
      "Topic: 0.017*\"crash\" + 0.012*\"polic\" + 0.009*\"miss\" + 0.009*\"search\" + 0.009*\"dead\" + 0.008*\"die\" + 0.008*\"driver\" + 0.008*\"woman\" + 0.008*\"kill\" + 0.007*\"fatal\"\n",
      "\n",
      "Score: 0.020003212615847588\t \n",
      "Topic: 0.016*\"countri\" + 0.015*\"hour\" + 0.014*\"rural\" + 0.008*\"health\" + 0.007*\"fund\" + 0.007*\"nation\" + 0.006*\"plan\" + 0.006*\"council\" + 0.005*\"sport\" + 0.005*\"chang\"\n",
      "\n",
      "Score: 0.02000233717262745\t \n",
      "Topic: 0.007*\"monday\" + 0.007*\"june\" + 0.006*\"islam\" + 0.006*\"april\" + 0.006*\"capit\" + 0.006*\"kill\" + 0.005*\"attack\" + 0.005*\"obama\" + 0.005*\"social\" + 0.005*\"anim\"\n",
      "\n",
      "Score: 0.020001178607344627\t \n",
      "Topic: 0.008*\"juli\" + 0.006*\"island\" + 0.006*\"stori\" + 0.005*\"quiz\" + 0.005*\"breakfast\" + 0.005*\"port\" + 0.005*\"histori\" + 0.004*\"fiji\" + 0.004*\"video\" + 0.004*\"music\"\n",
      "\n",
      "Score: 0.020000997930765152\t \n",
      "Topic: 0.015*\"trump\" + 0.009*\"leagu\" + 0.009*\"australia\" + 0.009*\"drum\" + 0.008*\"world\" + 0.008*\"final\" + 0.006*\"donald\" + 0.006*\"rugbi\" + 0.005*\"test\" + 0.005*\"cricket\"\n",
      "\n",
      "Score: 0.020000431686639786\t \n",
      "Topic: 0.009*\"interview\" + 0.007*\"michael\" + 0.007*\"wednesday\" + 0.007*\"thursday\" + 0.006*\"decemb\" + 0.006*\"sexual\" + 0.006*\"jam\" + 0.005*\"harvest\" + 0.005*\"quarter\" + 0.005*\"open\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5166648030281067\t Topic: 0.020*\"final\" + 0.017*\"farmer\" + 0.015*\"budget\" + 0.014*\"meet\" + 0.012*\"say\"\n",
      "Score: 0.34999850392341614\t Topic: 0.018*\"elect\" + 0.017*\"live\" + 0.012*\"turnbul\" + 0.012*\"life\" + 0.011*\"protest\"\n",
      "Score: 0.01666928268969059\t Topic: 0.021*\"market\" + 0.014*\"share\" + 0.014*\"servic\" + 0.013*\"health\" + 0.013*\"worker\"\n",
      "Score: 0.016667351126670837\t Topic: 0.026*\"govern\" + 0.022*\"trump\" + 0.021*\"plan\" + 0.017*\"countri\" + 0.016*\"council\"\n",
      "Score: 0.01666666753590107\t Topic: 0.024*\"south\" + 0.024*\"world\" + 0.019*\"coast\" + 0.018*\"australia\" + 0.016*\"women\"\n",
      "Score: 0.01666666753590107\t Topic: 0.054*\"polic\" + 0.020*\"death\" + 0.020*\"perth\" + 0.016*\"miss\" + 0.014*\"shoot\"\n",
      "Score: 0.01666666753590107\t Topic: 0.034*\"australia\" + 0.015*\"tasmania\" + 0.013*\"record\" + 0.012*\"break\" + 0.011*\"take\"\n",
      "Score: 0.01666666753590107\t Topic: 0.024*\"sydney\" + 0.018*\"interview\" + 0.018*\"adelaid\" + 0.014*\"arrest\" + 0.011*\"sentenc\"\n",
      "Score: 0.01666666753590107\t Topic: 0.037*\"australian\" + 0.029*\"queensland\" + 0.022*\"rural\" + 0.015*\"dead\" + 0.015*\"kill\"\n",
      "Score: 0.01666666753590107\t Topic: 0.035*\"charg\" + 0.031*\"court\" + 0.024*\"murder\" + 0.021*\"face\" + 0.018*\"die\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = 'How a Pentagon deal became an identity crisis for Google'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
