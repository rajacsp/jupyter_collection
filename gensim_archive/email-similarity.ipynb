{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raja.raman\\anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = [\n",
    "    \"The API should be the same so I don’t expect it to take much time, we’ll just need to review it to see if they are using User ID anywhere since for ES we use USN.\",\n",
    "    \"Unfortunately, we have received news from the studio that they will not be able to add all the items required for the migration in-time, meaning that the migration will have to be postponed to November (November 6). That being said, we asked HQ to still send us the main script so we can test it. We hope that we can continue on our own schedule in terms of preparations so we can finish everything and continue with other projects. Note that applying the GDPR changes will still have the same date (September 26). We will send a separate email regarding it soon.\",\n",
    "    \"As we are slowly approaching the merge date, I attached the updated WBS for the project. Please note that this is only regarding the merge, and that EU termination will be dealt with as a separate project. I believe we have covered everything, but please let me know if there is anything missing. What I would like to ask you is a confirmation regarding the tasks and the expected schedules for your respective teams.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The API should be the same so I don’t expect it to take much time, we’ll just need to review it to see if they are using User ID anywhere since for ES we use USN.',\n",
       " 'Unfortunately, we have received news from the studio that they will not be able to add all the items required for the migration in-time, meaning that the migration will have to be postponed to November (November 6). That being said, we asked HQ to still send us the main script so we can test it. We hope that we can continue on our own schedule in terms of preparations so we can finish everything and continue with other projects. Note that applying the GDPR changes will still have the same date (September 26). We will send a separate email regarding it soon.',\n",
       " 'As we are slowly approaching the merge date, I attached the updated WBS for the project. Please note that this is only regarding the merge, and that EU termination will be dealt with as a separate project. I believe we have covered everything, but please let me know if there is anything missing. What I would like to ask you is a confirmation regarding the tasks and the expected schedules for your respective teams.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents:\",len(raw_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'api', 'should', 'be', 'the', 'same', 'so', 'i', 'don', '’', 't', 'expect', 'it', 'to', 'take', 'much', 'time', ',', 'we', '’', 'll', 'just', 'need', 'to', 'review', 'it', 'to', 'see', 'if', 'they', 'are', 'using', 'user', 'id', 'anywhere', 'since', 'for', 'es', 'we', 'use', 'usn', '.'], ['unfortunately', ',', 'we', 'have', 'received', 'news', 'from', 'the', 'studio', 'that', 'they', 'will', 'not', 'be', 'able', 'to', 'add', 'all', 'the', 'items', 'required', 'for', 'the', 'migration', 'in-time', ',', 'meaning', 'that', 'the', 'migration', 'will', 'have', 'to', 'be', 'postponed', 'to', 'november', '(', 'november', '6', ')', '.', 'that', 'being', 'said', ',', 'we', 'asked', 'hq', 'to', 'still', 'send', 'us', 'the', 'main', 'script', 'so', 'we', 'can', 'test', 'it', '.', 'we', 'hope', 'that', 'we', 'can', 'continue', 'on', 'our', 'own', 'schedule', 'in', 'terms', 'of', 'preparations', 'so', 'we', 'can', 'finish', 'everything', 'and', 'continue', 'with', 'other', 'projects', '.', 'note', 'that', 'applying', 'the', 'gdpr', 'changes', 'will', 'still', 'have', 'the', 'same', 'date', '(', 'september', '26', ')', '.', 'we', 'will', 'send', 'a', 'separate', 'email', 'regarding', 'it', 'soon', '.'], ['as', 'we', 'are', 'slowly', 'approaching', 'the', 'merge', 'date', ',', 'i', 'attached', 'the', 'updated', 'wbs', 'for', 'the', 'project', '.', 'please', 'note', 'that', 'this', 'is', 'only', 'regarding', 'the', 'merge', ',', 'and', 'that', 'eu', 'termination', 'will', 'be', 'dealt', 'with', 'as', 'a', 'separate', 'project', '.', 'i', 'believe', 'we', 'have', 'covered', 'everything', ',', 'but', 'please', 'let', 'me', 'know', 'if', 'there', 'is', 'anything', 'missing', '.', 'what', 'i', 'would', 'like', 'to', 'ask', 'you', 'is', 'a', 'confirmation', 'regarding', 'the', 'tasks', 'and', 'the', 'expected', 'schedules', 'for', 'your', 'respective', 'teams', '.']]\n"
     ]
    }
   ],
   "source": [
    "gen_docs = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in raw_documents]\n",
    "print(gen_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(gen_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in dictionary: 133\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words in dictionary:\",len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 1), (28, 1), (29, 3), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 2)], [(0, 3), (1, 5), (5, 2), (9, 1), (13, 2), (19, 1), (23, 2), (26, 7), (27, 1), (29, 4), (34, 7), (36, 2), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 3), (49, 1), (50, 2), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 3), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 2), (66, 1), (67, 1), (68, 1), (69, 2), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 2), (85, 1), (86, 1), (87, 1), (88, 2), (89, 1), (90, 1), (91, 1), (92, 5), (93, 1), (94, 1), (95, 4), (96, 1)], [(0, 3), (1, 4), (4, 1), (5, 1), (9, 2), (10, 3), (12, 1), (26, 6), (29, 1), (34, 2), (40, 2), (44, 2), (51, 1), (53, 1), (57, 1), (68, 1), (79, 2), (85, 1), (92, 2), (95, 1), (96, 1), (97, 1), (98, 1), (99, 2), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 3), (110, 1), (111, 1), (112, 1), (113, 1), (114, 2), (115, 1), (116, 1), (117, 2), (118, 2), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = gensim.models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = gensim.similarities.Similarity('c:/test/',tf_idf[corpus],\n",
    "                                      num_features=len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_content = \"It was brought to our attention that in order to improve the communication and the planning for projects we should include other departments earlier in the planning stage. We generally think it is a good idea and it will save time and consume less resources on the long run.\"\n",
    "query_doc = [w.lower() for w in word_tokenize(new_content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'was', 'brought', 'to', 'our', 'attention', 'that', 'in', 'order', 'to', 'improve', 'the', 'communication', 'and', 'the', 'planning', 'for', 'projects', 'we', 'should', 'include', 'other', 'departments', 'earlier', 'in', 'the', 'planning', 'stage', '.', 'we', 'generally', 'think', 'it', 'is', 'a', 'good', 'idea', 'and', 'it', 'will', 'save', 'time', 'and', 'consume', 'less', 'resources', 'on', 'the', 'long', 'run', '.']\n"
     ]
    }
   ],
   "source": [
    "print(query_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc_bow = dictionary.doc2bow(query_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc_tf_idf = tf_idf[query_doc_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = sims[query_doc_tf_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ==> 14.74%\n",
      "1 ==> 24.55%\n",
      "2 ==> 15.52%\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for x in similarity:\n",
    "    print(str(counter) + \" ==> \" + str(\"%.2f\" % (x * 100)+\"%\") )\n",
    "    \n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
